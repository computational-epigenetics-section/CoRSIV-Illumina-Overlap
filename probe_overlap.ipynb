{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pybedtools import BedTool\n",
    "import os\n",
    "from functools import reduce\n",
    "\n",
    "ILLUMINA_DIR = \"/Users/antata/Library/CloudStorage/OneDrive-BaylorCollegeofMedicine/Illumina\" \n",
    "\n",
    "\"\"\"\n",
    "We used two sets of probe manifest files:\n",
    "\n",
    "1. Zhou Lab manifest files for probe coordinates, ID, and Gencode annotations\n",
    "HM450: https://github.com/zhou-lab/InfiniumAnnotationV1/raw/main/Anno/HM450/HM450.hg38.manifest.gencode.v36.tsv.gz\n",
    "EPIC: https://github.com/zhou-lab/InfiniumAnnotationV1/raw/main/Anno/EPIC/EPIC.hg38.manifest.gencode.v36.tsv.gz\n",
    "MSA: https://github.com/zhou-lab/InfiniumAnnotationV1/raw/main/Anno/MSA/MSA.hg38.manifest.gencode.v41.tsv.gz  \n",
    "\n",
    "\n",
    "2. Illumina manifest files for UCSC gene annotations\n",
    "HM450: https://webdata.illumina.com/downloads/productfiles/humanmethylation450/humanmethylation450_15017482_v1-2.csv\n",
    "EPIC: https://webdata.illumina.com/downloads/productfiles/methylationEPIC/infinium-methylationepic-v-1-0-b5-manifest-file-csv.zip\n",
    "MSA: https://support.illumina.com/content/dam/illumina-support/documents/downloads/productfiles/infiniummethylationscreening/MSA-48v1-0_20102838_A1.csv  \n",
    "\n",
    "Please download all files above and place them in ILLUMINA_DIR before running the code below.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_autosome(array_type):\n",
    "    \n",
    "    \"\"\"\n",
    "    Filters probe list to only include probes on chr1-22. Limit probes to those starting with cg or ch.\n",
    "    \n",
    "    Args:\n",
    "        type (string):\"HM450\", \"EPIC\", \"MSA\"\n",
    "    \"\"\"\n",
    "    \n",
    "    autosome = [\"chr\"+str(i) for i in range(1,23)]\n",
    "    ver = \"36\" if array_type != \"MSA\" else \"41\"\n",
    "    df = pd.read_csv(f\"{ILLUMINA_DIR}/{array_type}.hg38.manifest.gencode.v{ver}.tsv\", header=0, sep=\"\\t\")\n",
    "    df = df[df[\"probeID\"].apply(lambda x: x.startswith(\"cg\") or x.startswith(\"ch.\"))]\n",
    "    df = df[df[\"CpG_chrm\"].apply(lambda x: x in autosome)]\n",
    "    df = df[[\"CpG_chrm\", \"CpG_beg\", \"CpG_end\", \"probeID\"]]\n",
    "    df[\"CpG_beg\"] = df[\"CpG_beg\"].astype(int)\n",
    "    df[\"CpG_end\"] = df[\"CpG_end\"].astype(int)\n",
    "\n",
    "    # sort by chr then start pos\n",
    "    chr_order = {f'chr{i}': i for i in range(1, 23)}\n",
    "    df = df.sort_values(\n",
    "        by=['CpG_chrm', 'CpG_beg'],\n",
    "        key=lambda x: x.map(chr_order) if x.name == 'CpG_chrm' else x\n",
    "    )\n",
    "        \n",
    "    df.to_csv(f\"cleaned_data/illumina/{array_type}.hg38.bed\", sep=\"\\t\", index=0, header=0)\n",
    "    return df\n",
    "\n",
    "for array_type in [\"HM450\", \"EPIC\", \"MSA\"]:\n",
    "    filter_autosome(array_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "## Merge Illumina HM450, EPIC, MSA probes\n",
    "cd cleaned_data/illumina\n",
    "cat HM450.hg38.bed EPIC.hg38.bed MSA.hg38.bed | sort -k1,1 -k2,2n | bedtools merge -i - -d -1 -c 4 -o distinct > HM450_EPIC_MSA.clean.bed\n",
    "cat HM450.hg38.bed  EPIC.hg38.bed| sort -k1,1 -k2,2n | bedtools merge -i - -d -1 -c 4 -o distinct > HM450_EPIC.clean.bed\n",
    "sort -k1,1 -k2,2n HM450.hg38.bed | bedtools merge -i - -d -1 -c 4 -o distinct > HM450.clean.bed\n",
    "sort -k1,1 -k2,2n EPIC.hg38.bed | bedtools merge -i - -d -1 -c 4 -o distinct > EPIC.clean.bed\n",
    "sort -k1,1 -k2,2n MSA.hg38.bed | bedtools merge -i - -d -1 -c 4 -o distinct > MSA.clean.bed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get ESS, ME, SIV, CoRSIV bed files based on supplementary tables\n",
    "\n",
    "# ESS\n",
    "ess = pd.read_excel(\"input_data/ESS-2018.xlsx\", sheet_name=\"Table S7\")\n",
    "ess[\"id\"] = ess.apply(lambda x: f\"ESS_{x['Chromosome']}_{x['Start']}_{x['Stop']}_{x['Genes']}\" if str(x['Genes'])!=\"nan\" else f\"ESS_{x['Chromosome']}_{x['Start']}_{x['Stop']}_\", axis=1)\n",
    "ess[\"Start\"] -= 1\n",
    "ess = ess[[\"Chromosome\", \"Start\", \"Stop\", \"id\"]]\n",
    "ess.to_csv(\"input_data/ESS.hg19.bed\", sep=\"\\t\", header=0, index=0)\n",
    "\n",
    "# SIV\n",
    "siv = pd.read_excel(\"input_data/ESS-2018.xlsx\", sheet_name=\"Table S9\")\n",
    "siv[\"id\"] = siv.apply(lambda x: f\"SIV_{x['Chromosome']}_{x['Start']}_{x['Stop']}_{x['Genes']}\" if str(x['Genes'])!=\"nan\" else f\"SIV_{x['Chromosome']}_{x['Start']}_{x['Stop']}_\", axis=1)\n",
    "siv[\"Start\"] -= 1\n",
    "siv = siv[[\"Chromosome\", \"Start\", \"Stop\", \"id\"]]\n",
    "siv.to_csv(\"input_data/SIV.hg19.bed\", sep=\"\\t\", header=0, index=0)\n",
    "\n",
    "# ME\n",
    "me = pd.read_excel(\"input_data/SIV-2015.xlsx\", sheet_name=\"Supplementary Table 1\")\n",
    "# excluded_regions = [\"chr15:22095001-22095200\", \"chr8:142819201-142819400\"]\n",
    "me = me[me[\"C01_HF Total CpG sites\"]>5]\n",
    "me[[\"Chr\", \"Coord\"]] = me[\"UCSC browser coordinates\"].str.split(\":\", expand=True)\n",
    "me[[\"Start\", \"End\"]] = me[\"Coord\"].str.split(\"-\", expand=True)\n",
    "me[\"id\"] = me.apply(lambda x: f\"ME_GB2015_{x['UCSC browser coordinates']}\", axis=1)\n",
    "me[\"Start\"] = me[\"Start\"].astype(int)\n",
    "me[\"End\"] = me[\"End\"].astype(int)\n",
    "me[\"Start\"] -= 1\n",
    "me = me[[\"Chr\", \"Start\", \"End\", \"id\"]].reset_index(drop=True)\n",
    "me.to_csv(\"input_data/ME.hg19.bed\", sep=\"\\t\", header=0, index=0)\n",
    "\n",
    "# CoRSIV\n",
    "corsiv = pd.read_excel(\"input_data/CoRSIV-2019.xls\", sheet_name=\"S3\")\n",
    "corsiv[[\"Chr\", \"Coord\"]] = corsiv[\"USCS_Coordinates_CoRSIV\"].str.split(\":\", expand=True)\n",
    "corsiv[[\"Start\", \"End\"]] = corsiv[\"Coord\"].str.split(\"-\", expand=True)\n",
    "corsiv.drop_duplicates(subset=[\"Uniq_ID\"], inplace=True)\n",
    "corsiv[\"Start\"] = corsiv[\"Start\"].astype(float).astype(int)\n",
    "corsiv[\"End\"] = corsiv[\"End\"].astype(float).astype(int)\n",
    "corsiv = corsiv[[\"Chr\", \"Start\", \"End\", \"Uniq_ID\"]].reset_index(drop=True)\n",
    "corsiv.to_csv(\"input_data/corsiv2019.txt\", sep=\"\\t\", header=0, index=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Merge ME, SIV, ESS, CoRSIV regions. For ME,SIV,ESS regions, hg19 coordinates are converted to hg38 coordinates.\n",
    "\"\"\"\n",
    "\n",
    "cd input_data\n",
    "cat corsiv2019.txt ESS.hg38.bed ME.hg38.bed SIV.hg38.bed | sort -k1,1 -k2,2n | bedtools merge -i - -d -1 -c 4 -o distinct > all_corsiv_regions.merged.bed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter for regions on chr1-chr22 then pad regions on both ends to have a size with multiple of 100\n",
    "df = pd.read_csv(\"input_data/all_corsiv_regions.merged.bed\", sep=\"\\t\", names=[\"chr\", \"start\", 'end', \"id\"])\n",
    "# autosomes only\n",
    "autosome = [\"chr\"+str(i) for i in range(1,23)]\n",
    "df = df[df[\"chr\"].apply(lambda x: x in autosome)]\n",
    "\n",
    "df[\"new_id\"] = df.apply(lambda x: f\"{str(x['chr'])[3:]}_{x['start']}_{x['end']}\", axis=1)\n",
    "df[\"block_size\"] = df['end'] - df[\"start\"]\n",
    "\n",
    "# regions with new_id 19_40223366_40223480 and 19_40223493_40223693 will overlap after padding individually, so we merge them first\n",
    "merge_ids = ['19_40223366_40223480', '19_40223493_40223693']\n",
    "merge_rows = df[df['new_id'].isin(merge_ids)]\n",
    "new_start = merge_rows['start'].min()\n",
    "new_end = merge_rows['end'].max()\n",
    "new_id = f\"19_{new_start}_{new_end}\"\n",
    "merged_ids = ','.join(merge_rows['id'].tolist())\n",
    "\n",
    "new_row = {\n",
    "    'chr': 'chr19',\n",
    "    'start': new_start,\n",
    "    'end': new_end,\n",
    "    'new_id': new_id,\n",
    "    'id': merged_ids,\n",
    "    'block_size': new_end - new_start\n",
    "}\n",
    "\n",
    "df = df[~df['new_id'].isin(merge_ids)]\n",
    "df = df._append(new_row, ignore_index=True)\n",
    "  \n",
    "def pad_to_hundred(row):\n",
    "    \"\"\"\n",
    "    Pads each row (region) so that min(end-start) = 200 and (end-start) % 100 = 0.\n",
    "    \"\"\"\n",
    "    pad_size = (100 - (row['block_size'] % 100)) % 100\n",
    "    if row[\"block_size\"] + pad_size == 100:\n",
    "        pad_size += 100\n",
    "    row['start'] -= (pad_size // 2 + (pad_size % 2)) # pad start with one more bp if odd original block size\n",
    "    row[\"end\"] += pad_size // 2\n",
    "    row[\"block_size\"] = row[\"end\"] - row[\"start\"]\n",
    "    return row\n",
    "df = df.apply(pad_to_hundred, axis=1)\n",
    "\n",
    "# sort by chr then start pos\n",
    "chr_order = {f'chr{i}': i for i in range(1, 23)}\n",
    "df = df.sort_values(\n",
    "    by=['chr', 'start'],\n",
    "    key=lambda x: x.map(chr_order) if x.name == 'chr' else x\n",
    ")\n",
    "df[[\"chr\", \"start\", \"end\", \"new_id\", \"id\"]].to_csv(\"cleaned_data/regions/corsiv_regions_autosome_padded.bed\", sep=\"\\t\", index=0, header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sanity check on padded corsivs\n",
    "print(df[(df[\"block_size\"]%100!=0) | (df[\"block_size\"] < 200)].to_string()) \n",
    "temp = BedTool.from_dataframe(df[[\"chr\", \"start\", \"end\", \"new_id\"]])\n",
    "res = temp.intersect(temp, wa=True, c=True)\n",
    "res = res.to_dataframe(names=[\"chr\", \"start\", \"end\", \"new_id\", \"count\"])\n",
    "res[res[\"count\"]>1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = []\n",
    "for i in range(1, 11):\n",
    "    df = pd.read_csv(f\"cleaned_data/regions/control_regions_{i}.bed\", sep=\"\\t\", names=[\"chr\", \"start\", \"end\", \"id\"])\n",
    "    dfs.append(df)\n",
    "df = pd.concat(dfs, axis=0).reset_index(drop=True)\n",
    "df['sort_key'] = df['id'].apply(lambda x: (int(x.split('_')[0]), int(x.split('_')[1]), int(x.split('_')[-1])))\n",
    "df.sort_values(by='sort_key', inplace=True)\n",
    "df.drop('sort_key', axis=1, inplace=True)\n",
    "df.to_csv(\"cleaned_data/regions/control_regions_all.bed\", sep=\"\\t\", index=0, header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "## Get overlap CoRSIV and Control probes\n",
    "\n",
    "cd cleaned_data\n",
    "for i in HM450 EPIC MSA HM450_EPIC HM450_EPIC_MSA; do\n",
    "    bedtools intersect -a \"illumina/${i}.clean.bed\" -b regions/corsiv_regions_autosome_padded.bed -wa -wb > \"probes/corsiv_${i:l}_probes.bed\"\n",
    "\n",
    "bedtools intersect -a illumina/HM450_EPIC.clean.bed -b regions/control_regions_all.bed -wa -wb > probes/control_HM450_EPIC_probes_all.bed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"cleaned_data/probes/control_HM450_EPIC_probes_all.bed\", sep=\"\\t\", names=[\"chr\", \"start\", \"end\", \"id\", \"region_chr\", \"region_start\", \"region_end\", \"region_id\"])\n",
    "grouped = df.groupby(df['region_id'].str.split('_').str[-1])\n",
    "for i in range(1, 11):\n",
    "    group = grouped.get_group(str(i))\n",
    "    group.to_csv(f'cleaned_data/probes/control_HM450_EPIC_probes_{i}.bed', sep='\\t', index=False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "corsiv_probe_df = pd.read_csv(\"cleaned_data/probes/corsiv_HM450_EPIC_probes.bed\", sep=\"\\t\", names=[\"Probe_Chr\", \"Probe_Start\", \"Probe_End\", \"Probe_ID\", \"CoRSIV_Chr\", \"CoRSIV_Start\", \"CoRSIV_End\", \"CoRSIV_ID1\", \"CoRSIV_ID2\"])\n",
    "\n",
    "hm450_manifest = pd.read_csv(f\"{ILLUMINA_DIR}/humanmethylation450_15017482_v1-2.csv\", skiprows=7)\n",
    "hm450_manifest = hm450_manifest[[\"Name\", 'UCSC_RefGene_Name', 'UCSC_RefGene_Group']]\n",
    "hm450_base = pd.read_csv(\"cleaned_data/illumina/HM450.hg38.bed\", sep=\"\\t\", names=[\"CHR_hg38\", \"Start_hg38\", \"End_hg38\", \"Name\"])\n",
    "hm450_manifest = hm450_manifest.merge(hm450_base, on=[\"Name\"])\n",
    "hm450_manifest = hm450_manifest[[\"Name\", 'UCSC_RefGene_Name', 'UCSC_RefGene_Group', 'CHR_hg38', 'Start_hg38', 'End_hg38']]\n",
    "hm450_cleaned = pd.merge(hm450_manifest, corsiv_probe_df, left_on=[\"Name\", 'CHR_hg38', 'Start_hg38', 'End_hg38'], right_on=[\"Probe_ID\", \"Probe_Chr\", \"Probe_Start\", \"Probe_End\"])\n",
    "\n",
    "epic_manifest = pd.read_csv(f\"{ILLUMINA_DIR}/infinium-methylationepic-v-1-0-b5-manifest-file.csv\", skiprows=7)\n",
    "epic_manifest = epic_manifest[[\"Name\", 'UCSC_RefGene_Name', 'UCSC_RefGene_Group', 'CHR_hg38', 'Start_hg38', 'End_hg38']]\n",
    "epic_cleaned = pd.merge(epic_manifest, corsiv_probe_df, left_on=[\"Name\", 'CHR_hg38', 'Start_hg38', 'End_hg38'], right_on=[\"Probe_ID\", \"Probe_Chr\", \"Probe_Start\", \"Probe_End\"])\n",
    "\n",
    "manifest_annotation = pd.concat([epic_cleaned, hm450_cleaned])\n",
    "manifest_annotation.drop_duplicates(inplace=True)\n",
    "manifest_annotation.loc[\n",
    "    (manifest_annotation[\"UCSC_RefGene_Name\"].isna()) & (manifest_annotation[\"UCSC_RefGene_Group\"].isna()),\n",
    "    \"UCSC_RefGene_Group\"\n",
    "] = \"Intergenic\"    \n",
    "manifest_annotation[\"Unique_UCSC_RefGene_Name\"] = manifest_annotation[\"UCSC_RefGene_Name\"].apply(lambda x: \";\".join(set(x.split(\";\"))) if isinstance(x, str) else \"\")\n",
    "manifest_annotation[\"Unique_UCSC_RefGene_Group\"] = manifest_annotation[\"UCSC_RefGene_Group\"].apply(lambda x: \";\".join(set(x.split(\";\"))) if isinstance(x, str) else \"\")\n",
    "manifest_annotation.drop(columns=[\"Name\", 'CHR_hg38', 'Start_hg38', 'End_hg38'], inplace=True)\n",
    "\n",
    "\n",
    "epic_gencode = pd.read_csv(f\"{ILLUMINA_DIR}/EPIC.hg38.manifest.gencode.v36.tsv\", sep=\"\\t\")\n",
    "hm450_gencode = pd.read_csv(f\"{ILLUMINA_DIR}/HM450.hg38.manifest.gencode.v36.tsv\", sep=\"\\t\")\n",
    "gencode_annotation = pd.concat([epic_gencode, hm450_gencode])\n",
    "gencode_annotation.drop_duplicates(inplace=True)\n",
    "gencode_annotation.rename(columns={\"CpG_chrm\": \"Probe_Chr\", \"CpG_beg\": \"Probe_Start\", \"CpG_end\": \"Probe_End\", \"probeID\": \"Probe_ID\", 'genesUniq': \"Unique_GencodeV36_Name\"}, inplace=True)\n",
    "gencode_annotation = gencode_annotation[[\"Probe_ID\", \"Probe_Chr\", \"Probe_Start\", \"Probe_End\", 'Unique_GencodeV36_Name']]\n",
    "corsiv_annotated = pd.merge(gencode_annotation, manifest_annotation, on=[\"Probe_ID\", \"Probe_Chr\", \"Probe_Start\", \"Probe_End\"])\n",
    "corsiv_annotated['EPIC'] = corsiv_annotated.apply(lambda row: tuple(row[['Probe_Chr', 'Probe_Start', 'Probe_End', 'Probe_ID']]) in set(map(tuple, epic_cleaned[['CHR_hg38', 'Start_hg38', 'End_hg38', 'Name']].values)), axis=1)\n",
    "corsiv_annotated['HM450'] = corsiv_annotated.apply(lambda row: tuple(row[['Probe_Chr', 'Probe_Start', 'Probe_End', 'Probe_ID']]) in set(map(tuple, hm450_cleaned[['CHR_hg38', 'Start_hg38', 'End_hg38', 'Name']].values)), axis=1)\n",
    "\n",
    "# Create columns to store corresponding IDs from CoRSIV_ID2\n",
    "corsiv_annotated['ESS_ID'] = corsiv_annotated['CoRSIV_ID2'].apply(lambda x: ','.join([id for id in x.split(',') if id.split('_')[0] == 'ESS']))\n",
    "corsiv_annotated['CoRSIV2019_ID'] = corsiv_annotated['CoRSIV_ID2'].apply(lambda x: ','.join([id for id in x.split(',') if id.split('_')[0].isnumeric()]))\n",
    "corsiv_annotated['ME_ID'] = corsiv_annotated['CoRSIV_ID2'].apply(lambda x: ','.join([id for id in x.split(',') if id.split('_')[0] == 'ME']))\n",
    "corsiv_annotated['SIV_ID'] = corsiv_annotated['CoRSIV_ID2'].apply(lambda x: ','.join([id for id in x.split(',') if id.split('_')[0] == 'SIV']))\n",
    "\n",
    "# Display the updated dataframe\n",
    "corsiv_annotated = corsiv_annotated[['Probe_ID', 'Probe_Chr', 'Probe_Start', 'Probe_End',\n",
    "       'Unique_GencodeV36_Name', 'Unique_UCSC_RefGene_Name', 'Unique_UCSC_RefGene_Group',\n",
    "       'UCSC_RefGene_Name', 'UCSC_RefGene_Group',\n",
    "       'CoRSIV_Chr', 'CoRSIV_Start', 'CoRSIV_End', 'CoRSIV_ID1', 'EPIC',\n",
    "       'HM450', 'ME_ID', 'SIV_ID', 'ESS_ID', 'CoRSIV2019_ID']]\n",
    "corsiv_annotated.rename(columns={'CoRSIV_ID1': 'CoRSIV_ID'}, inplace=True)\n",
    "\n",
    "# Sort the DataFrame\n",
    "chr_order = {f'chr{i}': i for i in range(1, 23)}\n",
    "corsiv_annotated = corsiv_annotated.sort_values(\n",
    "    by=['Probe_Chr', 'Probe_Start'],\n",
    "    key=lambda x: x.map(chr_order) if x.name == 'Probe_Chr' else x\n",
    ")\n",
    "corsiv_annotated.to_csv(\"data_summary/corsiv_annotated_manifest.csv\", index=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Table 1 from data_summary/illumina_probe_overlap_summary.xlsx\n",
    "array_types = [\"HM450\", \"EPIC\", \"MSA\", \"HM450 U EPIC\", \"HM450 U EPIC U MSA\"]\n",
    "probe_counts = []\n",
    "for name in array_types:\n",
    "    df = pd.read_csv(f\"cleaned_data/illumina/{name.replace(' U ', '_')}.clean.bed\", sep=\"\\t\", names=[\"chr\", \"start\", \"end\", \"id\"])\n",
    "    probe_counts.append(df.shape[0])\n",
    "pd.DataFrame({\"array_type\": array_types, \"probe_count\": probe_counts})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Table 2 from data_summary/illumina_probe_overlap_summary.xlsx\n",
    "region_type = [\"ME\", \"SIV\", \"ESS\", \"CoRSIV2019\", \"All CoRSIVs\"]\n",
    "files = [\"input_data/ME.hg38.bed\", \"input_data/SIV.hg38.bed\", \"input_data/ESS.hg38.bed\", \"input_data/corsiv2019.txt\", \"cleaned_data/regions/corsiv_regions_autosome_padded.bed\"]\n",
    "region_counts = []\n",
    "autosome = [\"chr\"+str(i) for i in range(1,23)]\n",
    "for i, r in enumerate(files):\n",
    "    n = [\"chr\", \"start\", \"end\", \"id\"] if i < 4 else [\"chr\", \"start\", \"end\", \"id1\", \"id2\"]\n",
    "    df = pd.read_csv(r, sep=\"\\t\", names=n)\n",
    "    df = df[df[\"chr\"].isin(autosome)]\n",
    "    region_counts.append(df.shape[0])\n",
    "pd.DataFrame({\"region_type\": region_type, \"region_count\": region_counts})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Table 3 from data_summary/illumina_probe_overlap_summary.xlsx\n",
    "array_types = [\"HM450\", \"EPIC\", \"MSA\", \"HM450 U EPIC\", \"HM450 U EPIC U MSA\"]\n",
    "probe_counts = []\n",
    "for name in array_types:\n",
    "    df = pd.read_csv(f\"cleaned_data/probes/corsiv_{name.replace(' U ', '_')}_probes.bed\", sep=\"\\t\", names=[\"chr\", \"start\", \"end\", \"id\", \"region_chr\", \"region_start\", \"region_end\", \"region_id\", \"region_id2\"])\n",
    "    probe_counts.append(df.shape[0])\n",
    "pd.DataFrame({\"array_type\": array_types, \"probe_count\": probe_counts})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Table 5 from data_summary/illumina_probe_overlap_summary.xlsx\n",
    "array_types = [\"HM450\", \"EPIC\", \"MSA\", \"HM450 U EPIC\", \"HM450 U EPIC U MSA\"]\n",
    "probe_counts = []\n",
    "for name in array_types:\n",
    "    df = pd.read_csv(f\"cleaned_data/probes/corsiv_{name.replace(' U ', '_')}_probes.bed\", sep=\"\\t\", names=[\"chr\", \"start\", \"end\", \"id\", \"region_chr\", \"region_start\", \"region_end\", \"region_id\", \"region_id2\"])\n",
    "    probe_counts.append(len(set(df[\"region_id2\"])))\n",
    "pd.DataFrame({\"array_type\": array_types, \"probe_count\": probe_counts})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Define common column names and file paths\n",
    "col_names = [\"chr\", \"start\", \"end\", \"id\"]\n",
    "files = {\n",
    "    \"ME\": \"input_data/ME.hg38.bed\",\n",
    "    \"SIV\": \"input_data/SIV.hg38.bed\", \n",
    "    \"ESS\": \"input_data/ESS.hg38.bed\",\n",
    "    \"CoRSIV2019\": \"input_data/corsiv2019.txt\"\n",
    "}\n",
    "\n",
    "# Read files and add coordinates column\n",
    "dfs = {}\n",
    "for name, path in files.items():\n",
    "    df = pd.read_csv(path, sep=\"\\t\", names=col_names)\n",
    "    df[\"coords\"] = df[\"chr\"] + \":\" + df[\"start\"].astype(str) + \"-\" + df[\"end\"].astype(str)\n",
    "    dfs[name] = df\n",
    "\n",
    "# Create columns to store corresponding IDs from CoRSIV_ID2\n",
    "corsiv_annotated = pd.read_excel(\"data_summary/annotated_corsiv_all.xlsx\").iloc[:, :9]\n",
    "corsiv_bed = pd.read_csv(\"cleaned_data/regions/corsiv_regions_autosome_padded.bed\", sep=\"\\t\", names=[\"chr\", \"start\", \"end\", \"CoRSIV_ID\", \"original_id\"])[[\"CoRSIV_ID\", \"original_id\"]]\n",
    "corsiv_annotated = pd.merge(corsiv_annotated, corsiv_bed, on=\"CoRSIV_ID\", how=\"left\")\n",
    "corsiv_annotated['ME'] = corsiv_annotated['original_id'].apply(lambda x: ','.join([id for id in x.split(',') if id.split('_')[0] == 'ME']))\n",
    "corsiv_annotated['SIV'] = corsiv_annotated['original_id'].apply(lambda x: ','.join([id for id in x.split(',') if id.split('_')[0] == 'SIV']))\n",
    "corsiv_annotated['ESS'] = corsiv_annotated['original_id'].apply(lambda x: ','.join([id for id in x.split(',') if id.split('_')[0] == 'ESS']))\n",
    "corsiv_annotated['CoRSIV2019'] = corsiv_annotated['original_id'].apply(lambda x: ','.join([id for id in x.split(',') if id.split('_')[0].isnumeric()]))\n",
    "corsiv_annotated.drop(columns=[\"original_id\"], inplace=True)\n",
    "corsiv_annotated\n",
    "# Create new columns for coordinates from each dataset\n",
    "for name in ['ME', 'SIV', 'ESS', 'CoRSIV2019']:\n",
    "    # Create empty column\n",
    "    corsiv_annotated[f'{name}_COORDS'] = ''\n",
    "    \n",
    "    # For each row, look up coordinates if ID exists\n",
    "    # Create lookup dictionary for faster access\n",
    "    id_to_coords = {}\n",
    "    if name in dfs:\n",
    "        id_to_coords = dict(zip(dfs[name]['id'], dfs[name]['coords']))\n",
    "    \n",
    "    # Process all rows at once using pandas operations\n",
    "    corsiv_annotated[f'{name}_COORDS'] = corsiv_annotated[f'{name}'].apply(\n",
    "        lambda x: ','.join([id_to_coords.get(id, '') for id in x.split(',')]) if x else ''\n",
    "    )\n",
    "# Convert columns to boolean based on whether they contain strings or are empty\n",
    "corsiv_annotated[['ME', 'SIV', 'ESS', 'CoRSIV2019']] = corsiv_annotated[['ME', 'SIV', 'ESS', 'CoRSIV2019']].notna() & (corsiv_annotated[['ME', 'SIV', 'ESS', 'CoRSIV2019']] != '')\n",
    "corsiv_annotated.to_csv(f\"data_summary/annotated_corsiv_all.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
